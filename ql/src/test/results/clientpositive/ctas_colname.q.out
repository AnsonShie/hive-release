PREHOOK: query: -- HIVE-4392, column alias from expressionRR (GBY, etc.) is not valid column name for table
-- use internal name as col name

-- group by
explain
create table summary as select *, sum(key), count(value) from src
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: -- HIVE-4392, column alias from expressionRR (GBY, etc.) is not valid column name for table
-- use internal name as col name

-- group by
explain
create table summary as select *, sum(key), count(value) from src
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME summary) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_FUNCTION sum (TOK_TABLE_OR_COL key))) (TOK_SELEXPR (TOK_FUNCTION count (TOK_TABLE_OR_COL value)))))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-3 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Select Operator
              expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              outputColumnNames: key, value
              Group By Operator
                aggregations:
                      expr: sum(key)
                      expr: count(value)
                bucketGroup: false
                mode: hash
                outputColumnNames: _col0, _col1
                Reduce Output Operator
                  sort order: 
                  tag: -1
                  value expressions:
                        expr: _col0
                        type: double
                        expr: _col1
                        type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: sum(VALUE._col0)
                expr: count(VALUE._col1)
          bucketGroup: false
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col0
                  type: double
                  expr: _col1
                  type: bigint
                  expr: _col0
                  type: double
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1, _col2, _col3
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.summary

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: _col0 double, _col1 bigint, _c1 double, _c2 bigint
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: summary
          isExternal: false

  Stage: Stage-2
    Stats-Aggr Operator


PREHOOK: query: create table summary as select *, sum(key), count(value) from src
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table summary as select *, sum(key), count(value) from src
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@summary
PREHOOK: query: describe formatted summary
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted summary
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
_col0               	double              	None                
_col1               	bigint              	None                
_c1                 	double              	None                
_c2                 	bigint              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Protect Mode:       	None                	 
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	1                   
	rawDataSize         	25                  
	totalSize           	26                  
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from summary
PREHOOK: type: QUERY
PREHOOK: Input: default@summary
#### A masked pattern was here ####
POSTHOOK: query: select * from summary
POSTHOOK: type: QUERY
POSTHOOK: Input: default@summary
#### A masked pattern was here ####
130091.0	500	130091.0	500
PREHOOK: query: -- window functions
explain
create table x4 as select *, rank() over(partition by key order by value) as rr from src1
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: -- window functions
explain
create table x4 as select *, rank() over(partition by key order by value) as rr from src1
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME x4) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_FUNCTION rank (TOK_WINDOWSPEC (TOK_PARTITIONINGSPEC (TOK_DISTRIBUTEBY (TOK_TABLE_OR_COL key)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value)))))) rr (TOK_WINDOWSPEC (TOK_PARTITIONINGSPEC (TOK_DISTRIBUTEBY (TOK_TABLE_OR_COL key)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))))))))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-3 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src1 
          TableScan
            alias: src1
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              sort order: ++
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: -1
              value expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
      Reduce Operator Tree:
        Extract
          PTF Operator
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _wcol0
                    type: int
              outputColumnNames: _col0, _col1, _col2
              File Output Operator
                compressed: false
                GlobalTableId: 1
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    name: default.x4

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: key string, value string, rr int
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: x4
          isExternal: false

  Stage: Stage-2
    Stats-Aggr Operator


PREHOOK: query: create table x4 as select *, rank() over(partition by key order by value) as rr from src1
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src1
POSTHOOK: query: create table x4 as select *, rank() over(partition by key order by value) as rr from src1
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@x4
PREHOOK: query: describe formatted x4
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted x4
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
rr                  	int                 	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Protect Mode:       	None                	 
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	25                  
	rawDataSize         	242                 
	totalSize           	267                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from x4
PREHOOK: type: QUERY
PREHOOK: Input: default@x4
#### A masked pattern was here ####
POSTHOOK: query: select * from x4
POSTHOOK: type: QUERY
POSTHOOK: Input: default@x4
#### A masked pattern was here ####
		1
		1
		1
		1
	val_165	5
	val_193	6
	val_265	7
	val_27	8
	val_409	9
	val_484	10
128		1
146	val_146	1
150	val_150	1
213	val_213	1
224		1
238	val_238	1
255	val_255	1
273	val_273	1
278	val_278	1
311	val_311	1
369		1
401	val_401	1
406	val_406	1
66	val_66	1
98	val_98	1
PREHOOK: query: explain
create table x5 as select *, lead(key,1) over(partition by key order by value) from src limit 20
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: explain
create table x5 as select *, lead(key,1) over(partition by key order by value) from src limit 20
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME x5) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_FUNCTION lead (TOK_TABLE_OR_COL key) 1 (TOK_WINDOWSPEC (TOK_PARTITIONINGSPEC (TOK_DISTRIBUTEBY (TOK_TABLE_OR_COL key)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value)))))) (TOK_WINDOWSPEC (TOK_PARTITIONINGSPEC (TOK_DISTRIBUTEBY (TOK_TABLE_OR_COL key)) (TOK_ORDERBY (TOK_TABSORTCOLNAMEASC (TOK_TABLE_OR_COL value))))))) (TOK_LIMIT 20))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 depends on stages: Stage-2
  Stage-4 depends on stages: Stage-0
  Stage-3 depends on stages: Stage-4

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
              sort order: ++
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: -1
              value expressions:
                    expr: key
                    type: string
                    expr: value
                    type: string
      Reduce Operator Tree:
        Extract
          PTF Operator
            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _wcol0
                    type: string
              outputColumnNames: _col0, _col1, _col2
              Limit
                File Output Operator
                  compressed: false
                  GlobalTableId: 0
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
            Reduce Output Operator
              sort order: 
              tag: -1
              value expressions:
                    expr: _col0
                    type: string
                    expr: _col1
                    type: string
                    expr: _col2
                    type: string
      Reduce Operator Tree:
        Extract
          Limit
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.x5

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: key string, value string, tok_windowspec string
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: x5
          isExternal: false

  Stage: Stage-3
    Stats-Aggr Operator


PREHOOK: query: create table x5 as select *, lead(key,1) over(partition by key order by value) from src limit 20
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src
POSTHOOK: query: create table x5 as select *, lead(key,1) over(partition by key order by value) from src limit 20
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src
POSTHOOK: Output: default@x5
PREHOOK: query: describe formatted x5
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted x5
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
key                 	string              	None                
value               	string              	None                
tok_windowspec      	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Protect Mode:       	None                	 
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	20                  
	rawDataSize         	268                 
	totalSize           	288                 
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from x5
PREHOOK: type: QUERY
PREHOOK: Input: default@x5
#### A masked pattern was here ####
POSTHOOK: query: select * from x5
POSTHOOK: type: QUERY
POSTHOOK: Input: default@x5
#### A masked pattern was here ####
0	val_0	0
0	val_0	0
0	val_0	NULL
10	val_10	NULL
100	val_100	100
100	val_100	NULL
103	val_103	103
103	val_103	NULL
104	val_104	104
104	val_104	NULL
105	val_105	NULL
11	val_11	NULL
111	val_111	NULL
113	val_113	113
113	val_113	NULL
114	val_114	NULL
116	val_116	NULL
118	val_118	118
118	val_118	NULL
119	val_119	119
PREHOOK: query: -- sub query
explain
create table x6 as select * from (select *, max(key) from src1) a
PREHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: query: -- sub query
explain
create table x6 as select * from (select *, max(key) from src1) a
POSTHOOK: type: CREATETABLE_AS_SELECT
ABSTRACT SYNTAX TREE:
  (TOK_CREATETABLE (TOK_TABNAME x6) TOK_LIKETABLE (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF) (TOK_SELEXPR (TOK_FUNCTION max (TOK_TABLE_OR_COL key)))))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1
  Stage-3 depends on stages: Stage-0
  Stage-2 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a:src1 
          TableScan
            alias: src1
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: key
              Group By Operator
                aggregations:
                      expr: max(key)
                bucketGroup: false
                mode: hash
                outputColumnNames: _col0
                Reduce Output Operator
                  sort order: 
                  tag: -1
                  value expressions:
                        expr: _col0
                        type: string
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: max(VALUE._col0)
          bucketGroup: false
          mode: mergepartial
          outputColumnNames: _col0
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col0
                  type: string
            outputColumnNames: _col0, _col1
            File Output Operator
              compressed: false
              GlobalTableId: 1
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  name: default.x6

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-3
      Create Table Operator:
        Create Table
          columns: _col0 string, _c1 string
          if not exists: false
          input format: org.apache.hadoop.mapred.TextInputFormat
          # buckets: -1
          output format: org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat
          name: x6
          isExternal: false

  Stage: Stage-2
    Stats-Aggr Operator


PREHOOK: query: create table x6 as select * from (select *, max(key) from src1) a
PREHOOK: type: CREATETABLE_AS_SELECT
PREHOOK: Input: default@src1
POSTHOOK: query: create table x6 as select * from (select *, max(key) from src1) a
POSTHOOK: type: CREATETABLE_AS_SELECT
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@x6
PREHOOK: query: describe formatted x6
PREHOOK: type: DESCTABLE
POSTHOOK: query: describe formatted x6
POSTHOOK: type: DESCTABLE
# col_name            	data_type           	comment             
	 	 
_col0               	string              	None                
_c1                 	string              	None                
	 	 
# Detailed Table Information	 	 
Database:           	default             	 
#### A masked pattern was here ####
Protect Mode:       	None                	 
Retention:          	0                   	 
#### A masked pattern was here ####
Table Type:         	MANAGED_TABLE       	 
Table Parameters:	 	 
	numFiles            	1                   
	numPartitions       	0                   
	numRows             	1                   
	rawDataSize         	5                   
	totalSize           	6                   
#### A masked pattern was here ####
	 	 
# Storage Information	 	 
SerDe Library:      	org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe	 
InputFormat:        	org.apache.hadoop.mapred.TextInputFormat	 
OutputFormat:       	org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat	 
Compressed:         	No                  	 
Num Buckets:        	-1                  	 
Bucket Columns:     	[]                  	 
Sort Columns:       	[]                  	 
Storage Desc Params:	 	 
	serialization.format	1                   
PREHOOK: query: select * from x6
PREHOOK: type: QUERY
PREHOOK: Input: default@x6
#### A masked pattern was here ####
POSTHOOK: query: select * from x6
POSTHOOK: type: QUERY
POSTHOOK: Input: default@x6
#### A masked pattern was here ####
98	98
